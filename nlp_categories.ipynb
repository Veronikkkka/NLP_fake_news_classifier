{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1F51FPcPpViBPFMpHQQeJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Veronikkkka/NLP_fake_news_classifier/blob/main/nlp_categories.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kAHRXR1W-AzN"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def analyze_numbers_in_text(article_text):\n",
        "    \"\"\"\n",
        "    Analyze the use of numbers in a given text and return a score.\n",
        "\n",
        "    Parameters:\n",
        "    - article_text (str): The text of the article to analyze.\n",
        "\n",
        "    Returns:\n",
        "    - dict: A dictionary containing:\n",
        "        - 'number_count': Total number of numerical tokens in the text.\n",
        "        - 'unique_number_count': Count of unique numbers.\n",
        "        - 'average_number_length': Average length of numerical tokens.\n",
        "        - 'number_score': A weighted score based on number analysis.\n",
        "    \"\"\"\n",
        "    number_pattern = r'\\b\\d+(?:\\.\\d+)?\\b'\n",
        "    numbers = re.findall(number_pattern, article_text)\n",
        "\n",
        "    number_count = len(numbers)\n",
        "    # print(numbers)\n",
        "    unique_numbers = set(numbers)\n",
        "    unique_number_count = len(unique_numbers)\n",
        "\n",
        "    average_number_length = (\n",
        "        sum(len(num) for num in numbers) / number_count if number_count > 0 else 0\n",
        "    )\n",
        "\n",
        "    number_score = (\n",
        "        0.5 * number_count + 0.3 * unique_number_count + 0.2 * average_number_length\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"number_count\": number_count,\n",
        "        \"unique_number_count\": unique_number_count,\n",
        "        \"average_number_length\": average_number_length,\n",
        "        \"number_score\": number_score\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "article = \"\"\"\n",
        "The population of the city is approximately 1.2 million as of 2023.\n",
        "In 2020, it was 1.15 million. The area is 234.5 square kilometers.\n",
        "\"\"\"\n",
        "result = analyze_numbers_in_text(article)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5915EELI-Qtm",
        "outputId": "1975b67e-91ce-4991-b3b2-a5a74f341ff6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1.2', '2023', '2020', '1.15', '234.5']\n",
            "{'number_count': 5, 'unique_number_count': 5, 'average_number_length': 4.0, 'number_score': 4.8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import unique\n",
        "import re\n",
        "\n",
        "def analyze_hyperlinks_in_text(article_text):\n",
        "    \"\"\"\n",
        "    Analyze the presence of hyperlinks in a given text and return a score.\n",
        "\n",
        "    Parameters:\n",
        "    - article_text (str): The text of the article to analyze.\n",
        "\n",
        "    Returns:\n",
        "    - dict: A dictionary containing:\n",
        "        - 'hyperlink_count': Total number of hyperlinks in the text.\n",
        "        - 'unique_hyperlink_count': Count of unique hyperlinks.\n",
        "        - 'hyperlink_score': A normalized score (0 to 1) based on hyperlink analysis.\n",
        "    \"\"\"\n",
        "    hyperlink_pattern = r'\\b(?:http[s]?://|www\\.)\\S+\\b'\n",
        "    hyperlinks = re.findall(hyperlink_pattern, article_text)\n",
        "\n",
        "    # Total number of hyperlinks\n",
        "    hyperlink_count = len(hyperlinks)\n",
        "\n",
        "    unique_hyperlinks = set(hyperlinks)\n",
        "    unique_hyperlink_count = len(unique_hyperlinks)\n",
        "\n",
        "    MAX_HYPERLINK_COUNT = 50  # Assumes a reasonable max count of links in an article\n",
        "    MAX_UNIQUE_LINK_COUNT = 50  # Assumes a reasonable max unique links in an article\n",
        "\n",
        "    # Normalized metrics\n",
        "    # normalized_hyperlink_count = min(hyperlink_count / MAX_HYPERLINK_COUNT, 1.0)\n",
        "    # normalized_unique_hyperlink_count = min(unique_hyperlink_count / MAX_UNIQUE_LINK_COUNT, 1.0)\n",
        "\n",
        "    # Weighted score calculation\n",
        "    hyperlink_score = (\n",
        "        0.7 * hyperlink_count +\n",
        "        0.3 * unique_hyperlink_count\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"hyperlink_count\": hyperlink_count,\n",
        "        \"unique_hyperlink_count\": unique_hyperlink_count,\n",
        "        \"hyperlink_score\": hyperlink_score\n",
        "    }\n"
      ],
      "metadata": {
        "id": "75ls9QWsAoOh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example usage\n",
        "article = \"\"\"\n",
        "This article includes some links like https://example.com and http://test.com.\n",
        "You can also visit www.website.org for more information.\n",
        "Another link is https://example.com/details.\n",
        "\"\"\"\n",
        "result = analyze_hyperlinks_in_text(article)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2r5axtmA5x9",
        "outputId": "ed7a9ee6-b150-40bc-db59-b5bf640dd508"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'hyperlink_count': 4, 'unique_hyperlink_count': 4, 'hyperlink_score': 4.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "def estimate_emotionality(article_text):\n",
        "    \"\"\"\n",
        "    Estimate the emotionality of a news article.\n",
        "\n",
        "    Parameters:\n",
        "    - article_text (str): The text of the article to analyze.\n",
        "\n",
        "    Returns:\n",
        "    - dict: A dictionary containing:\n",
        "        - 'sentiment_polarity': Sentiment polarity (-1 to 1).\n",
        "        - 'sentiment_subjectivity': Sentiment subjectivity (0 to 1).\n",
        "        - 'emotion_words_count': Count of words associated with emotions.\n",
        "        - 'emotionality_score': Normalized score (0 to 1) reflecting emotionality.\n",
        "    \"\"\"\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    words = [\n",
        "        word.lower()\n",
        "        for word in re.findall(r'\\b\\w+\\b', article_text)\n",
        "        if word.lower() not in stop_words\n",
        "    ]\n",
        "\n",
        "    # Sentiment analysis using TextBlob\n",
        "    blob = TextBlob(article_text)\n",
        "    sentiment_polarity = blob.sentiment.polarity\n",
        "    sentiment_subjectivity = blob.sentiment.subjectivity\n",
        "    # print(sentiment_subjectivity, type(sentiment_subjectivity))\n",
        "    emotion_words = {\n",
        "        \"happy\", \"joy\", \"sad\", \"anger\", \"fear\", \"love\", \"hate\", \"excited\",\n",
        "        \"nervous\", \"calm\", \"anxious\", \"worried\", \"delighted\", \"cry\", \"laugh\"\n",
        "    }\n",
        "    emotion_count = Counter(word for word in words if word in emotion_words)\n",
        "    emotion_words_count = sum(emotion_count.values())\n",
        "    # Normalized emotionality score\n",
        "    # MAX_POLARITY = 1.0  # Maximum absolute polarity\n",
        "    # MAX_SUBJECTIVITY = 1.0  # Maximum subjectivity\n",
        "    # MAX_EMOTION_WORDS = 50  # Reasonable max for emotion word count in typical news\n",
        "\n",
        "    # normalized_polarity = abs(sentiment_polarity) / MAX_POLARITY\n",
        "    # normalized_subjectivity = sentiment_subjectivity / MAX_SUBJECTIVITY\n",
        "    # normalized_emotion_words = min(emotion_words_count / MAX_EMOTION_WORDS, 1.0)\n",
        "\n",
        "    emotionality_score = (\n",
        "        0.4 * sentiment_polarity +\n",
        "        0.3 * sentiment_subjectivity +\n",
        "        0.3 * emotion_words_count\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"sentiment_polarity\": sentiment_polarity,\n",
        "        \"sentiment_subjectivity\": sentiment_subjectivity,\n",
        "        \"emotion_words_count\": emotion_words_count,\n",
        "        \"emotionality_score\": emotionality_score\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znpKYDqs4Vlo",
        "outputId": "acc535ea-6e8a-42e8-e796-0932b5b3623c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article = \"\"\"\n",
        "Breaking news: A massive earthquake has caused widespread devastation in the region.\n",
        "Many are anxious about the aftermath, while others are expressing love and solidarity.\n",
        "\"\"\"\n",
        "result = estimate_emotionality(article)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPy-G7L54kdH",
        "outputId": "eb0bd700-7643-4b49-bb41-9c19568c032d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sentiment_polarity': 0.1875, 'sentiment_subjectivity': 0.775, 'emotion_words_count': 2, 'emotionality_score': 0.9075}\n"
          ]
        }
      ]
    }
  ]
}